{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import os\n",
    "import io\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "training = \"C:\\\\Extras\\\\DataScience\\\\Hackathon1\\\\train.csv\"\n",
    "train_df = pd.read_csv(training, header = 0)\n",
    "\n",
    "final = \"C:\\\\Extras\\\\DataScience\\\\Hackathon1\\\\test.csv\"\n",
    "final_df = pd.read_csv(final, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#To check the first and last alphabet of the word is a valid entry\n",
    "\n",
    "train_df['LW'] = train_df['Word'].str[-1:]\n",
    "train_df['FW'] = train_df['Word'].str[:1]\n",
    "\n",
    "train_df['LW_chk'] = np.where(((train_df['LW'] == (\"(\",\")\",\"'\",\",\",\"`\",\"?\",\";\",\"-\",\":\",\"/\",\"’\",\"-\",\"[\",\"]\")) |\n",
    "                              train_df['LW'].str[0].str.isalnum()), 1, 0)\n",
    "train_df['FW_chk'] = np.where(((train_df['FW'] == (\"(\",\")\",\"'\",\",\",\"`\",\"?\",\";\",\"-\",\":\",\"/\",\"’\",\"-\",\"[\",\"]\")) |\n",
    "                              train_df['FW'].str[0].str.isalnum()), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "length=train_df.groupby('Sent_ID', as_index=False).agg(\"count\")\n",
    "train_df = train_df.merge(length, on = \"Sent_ID\", how=\"left\").drop(['Word_y','Doc_ID_y','tag_y','LW_y','FW_y',\n",
    "                                                                         'LW_chk_y','FW_chk_y'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns = {\"id_x\": \"id\", \"Doc_ID_x\":\"Doc_ID\", \"Word_x\": \"Word\",\n",
    "                                               \"tag_x\": \"tag\", \"LW_x\":\"LW\", \"FW_x\": \"FW\",\n",
    "                                               \"LW_chk_x\": \"LW_chk\", \"FW_chk_x\": \"FW_chk\", \"id_y\":\"count_sent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df['counter']=1\n",
    "train_df['counter'] = train_df.groupby('Sent_ID').counter.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To get the word's location in the sentence\n",
    "\n",
    "train_df['word_location']=train_df['counter']/train_df['count_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "      <th>LW</th>\n",
       "      <th>FW</th>\n",
       "      <th>LW_chk</th>\n",
       "      <th>FW_chk</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>counter</th>\n",
       "      <th>word_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "      <td>y</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "      <td>e</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag LW FW  LW_chk  FW_chk  count_sent  \\\n",
       "0   1       1        1        Obesity   O  y  O       1       1          15   \n",
       "1   2       1        1             in   O  n  i       1       1          15   \n",
       "2   3       1        1           Low-   O  -  L       0       1          15   \n",
       "3   4       1        1            and   O  d  a       1       1          15   \n",
       "4   5       1        1  Middle-Income   O  e  M       1       1          15   \n",
       "\n",
       "   counter  word_location  \n",
       "0        1       0.066667  \n",
       "1        2       0.133333  \n",
       "2        3       0.200000  \n",
       "3        4       0.266667  \n",
       "4        5       0.333333  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TRAINING: Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df[\"word_mapping\"]=train_df[\"word_location\"].apply(lambda x: \"SW\" if x<=0.01 else(\"LW\" if x>=0.99 else \"MW\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['words_combined'] = train_df[['Word', 'word_mapping']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df['Word']=train_df['words_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_df=train_df.fillna(0)\n",
    "train, test= train_test_split(train_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(train['Word'].values.astype('U'))\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = train['tag'].values\n",
    "targets_test=test['tag'].values\n",
    "\n",
    "classifier.fit(counts, targets)\n",
    "\n",
    "test_counts = vectorizer.transform(test['Word'].values.astype('U'))\n",
    "predictions = classifier.predict(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98300040347724027"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_results= classifier.score(test_counts, targets_test)\n",
    "scoring_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_df=test.copy(deep=True)\n",
    "test_df[\"tag\"]=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from copy import deepcopy\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Evaluation metric for Innoplexus NER Challenge\n",
    "\n",
    "def collect_named_entities(tokens): # Helper Function for score calculation\n",
    "    \"\"\"\n",
    "    Creates a list of Entity named-tuples, storing the entity type and the start and end\n",
    "    offsets of the entity.\n",
    "    :param tokens: a list of labels\n",
    "    :return: a list of Entity named-tuples\n",
    "    \"\"\"\n",
    "    Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n",
    "    named_entities = []\n",
    "    start_offset = None\n",
    "    end_offset = None\n",
    "    ent_type = None\n",
    "\n",
    "    for offset, token_tag in enumerate(tokens):\n",
    "\n",
    "        if token_tag == 'O':\n",
    "            if ent_type is not None and start_offset is not None:\n",
    "                end_offset = offset - 1\n",
    "                named_entities.append(Entity(ent_type, start_offset, end_offset))\n",
    "                start_offset = None\n",
    "                end_offset = None\n",
    "                ent_type = None\n",
    "\n",
    "        elif ent_type is None:\n",
    "            ent_type = token_tag[2:]\n",
    "            start_offset = offset\n",
    "\n",
    "        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n",
    "\n",
    "            end_offset = offset - 1\n",
    "            named_entities.append(Entity(ent_type, start_offset, end_offset))\n",
    "\n",
    "            # start of a new entity\n",
    "            ent_type = token_tag[2:]\n",
    "            start_offset = offset\n",
    "            end_offset = None\n",
    "\n",
    "    # catches an entity that goes up until the last token\n",
    "    if ent_type and start_offset and end_offset is None:\n",
    "        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n",
    "\n",
    "    return named_entities\n",
    "\n",
    "def compute_metrics(true_named_entities, pred_named_entities): # Helper Function for score calculation\n",
    "    eval_metrics = {'correct': 0, 'partial': 0, 'missed': 0, 'spurius': 0}\n",
    "    target_tags_no_schema = ['indications']\n",
    "\n",
    "    # overall results\n",
    "    evaluation = {'partial': deepcopy(eval_metrics)}\n",
    "\n",
    "\n",
    "    true_which_overlapped_with_pred = []  # keep track of entities that overlapped\n",
    "\n",
    "    # go through each predicted named-entity\n",
    "    for pred in pred_named_entities:\n",
    "        found_overlap = False\n",
    "\n",
    "        # check if there's an exact match, i.e.: boundary and entity type match\n",
    "        if pred in true_named_entities:\n",
    "            true_which_overlapped_with_pred.append(pred)\n",
    "            evaluation['partial']['correct'] += 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            # check for overlaps with any of the true entities\n",
    "            for true in true_named_entities:\n",
    "\n",
    "                \n",
    "                # 2. check for an overlap i.e. not exact boundary match, with true entities\n",
    "                if pred.start_offset <= true.end_offset and true.start_offset <= pred.end_offset:\n",
    "\n",
    "                    true_which_overlapped_with_pred.append(true)\n",
    "\n",
    "                    evaluation['partial']['partial'] += 1\n",
    "\n",
    "                    found_overlap = True\n",
    "                    break\n",
    "\n",
    "            # count spurius (i.e., False Positive) entities\n",
    "            if not found_overlap:\n",
    "                # overall results\n",
    "                evaluation['partial']['spurius'] += 1\n",
    "\n",
    "    # count missed entities (i.e. False Negative)\n",
    "    for true in true_named_entities:\n",
    "        if true in true_which_overlapped_with_pred:\n",
    "            continue\n",
    "        else:\n",
    "            # overall results\n",
    "            evaluation['partial']['missed'] += 1\n",
    "\n",
    "    # Compute 'possible', 'actual'\n",
    "    for eval_type in ['partial']:\n",
    "\n",
    "        correct = evaluation[eval_type]['correct']\n",
    "        partial = evaluation[eval_type]['partial']\n",
    "        missed = evaluation[eval_type]['missed']\n",
    "        spurius = evaluation[eval_type]['spurius']\n",
    "\n",
    "        # possible: nr. annotations in the gold-standard which contribute to the final score\n",
    "        evaluation[eval_type]['possible'] = correct + partial + missed\n",
    "\n",
    "        # actual: number of annotations produced by the NER system\n",
    "        evaluation[eval_type]['actual'] = correct + partial + spurius\n",
    "\n",
    "        actual = evaluation[eval_type]['actual']\n",
    "        possible = evaluation[eval_type]['possible']\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def list_converter(df): # Helper Function for score calculation\n",
    "    keys, values = df.sort_values('Sent_ID_x').values.T\n",
    "    ukeys, index = np.unique(keys,True)\n",
    "    lists = [list(array) for array in np.split(values,index[1:])]\n",
    "    return lists\n",
    "\n",
    "# ideal and pred respectively represent dataframes containing actual labels and predictions for the set of sentences in the test data. \n",
    "# It has the same format as the sample submission (id, Sent_ID, tag)\n",
    "\n",
    "def calculate_score(ideal, pred): # Calculates the final F1 Score\n",
    "\n",
    "    merged = ideal.merge(pred, on = \"id\", how=\"inner\").drop(['Sent_ID_y'],axis = 1)\n",
    "    \n",
    "    \n",
    "    # The scores are calculated sentence wise and then aggregated to calculate the overall score, for this\n",
    "    # List converter function groups the labels by sentence to generate a list of lists with each inner list representing a sentence in sequence\n",
    "    ideal_ = list_converter(merged.drop(['id','tag_y'],axis = 1))\n",
    "    pred_ = list_converter(merged.drop(['id','tag_x'],axis = 1))\n",
    "\n",
    "    metrics_results = {'correct': 0, 'partial': 0,\n",
    "                   'missed': 0, 'spurius': 0, 'possible': 0, 'actual': 0}\n",
    "\n",
    "    results = {'partial': deepcopy(metrics_results)}\n",
    "\n",
    "\n",
    "    for true_ents, pred_ents in zip(ideal_, pred_):    \n",
    "    # compute results for one sentence\n",
    "        tmp_results = compute_metrics(collect_named_entities(true_ents),collect_named_entities(pred_ents))\n",
    "    \n",
    "    # aggregate overall results\n",
    "        for eval_schema in results.keys():\n",
    "            for metric in metrics_results.keys():\n",
    "                results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
    "    correct = results['partial']['correct']\n",
    "    partial = results['partial']['partial']\n",
    "    missed = results['partial']['missed']\n",
    "    spurius = results['partial']['spurius']\n",
    "    actual = results['partial']['actual']\n",
    "    possible = results['partial']['possible']\n",
    "\n",
    "\n",
    "    precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n",
    "    recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n",
    "\n",
    "\n",
    "    score = (2 * precision * recall)/(precision + recall) if (precision + recall) >0 else 0\n",
    "    \n",
    "    # final score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4304018153641798"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2=test_df[['id','Sent_ID','tag']]\n",
    "test2=test[['id','Sent_ID','tag']]\n",
    "calculate_score(test2,test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_x          tag_y        \n",
       "B-indications  B-indications       5043\n",
       "               I-indications        552\n",
       "               O                  10411\n",
       "I-indications  B-indications        774\n",
       "               I-indications       1833\n",
       "               O                  10798\n",
       "O              B-indications        407\n",
       "               I-indications        231\n",
       "               O                1333101\n",
       "Name: (id, count), dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = test.merge(test_df, on = \"id\", how=\"inner\").drop(['Sent_ID_y','Word_y','Doc_ID_y'],axis = 1)\n",
    "check=merged.groupby(['tag_x', 'tag_y']).agg(['count'])\n",
    "check['id','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['tag'] = np.where(test_df['LW_chk']==0, 'O', test_df['tag'])\n",
    "test_df['tag'] = np.where(test_df['FW_chk']==0, 'O', test_df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4303590709005841"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2=test_df[['id','Sent_ID','tag']]\n",
    "test2=test[['id','Sent_ID','tag']]\n",
    "calculate_score(test2,test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_x          tag_y        \n",
       "B-indications  B-indications       5039\n",
       "               I-indications        552\n",
       "               O                  10415\n",
       "I-indications  B-indications        774\n",
       "               I-indications       1833\n",
       "               O                  10798\n",
       "O              B-indications        404\n",
       "               I-indications        223\n",
       "               O                1333112\n",
       "Name: (id, count), dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = test.merge(test_df, on = \"id\", how=\"inner\").drop(['Sent_ID_y','Word_y','Doc_ID_y'],axis = 1)\n",
    "check=merged.groupby(['tag_x', 'tag_y']).agg(['count'])\n",
    "check['id','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID_x</th>\n",
       "      <th>Sent_ID_x</th>\n",
       "      <th>Word_x</th>\n",
       "      <th>tag_x</th>\n",
       "      <th>LW_x</th>\n",
       "      <th>FW_x</th>\n",
       "      <th>LW_chk_x</th>\n",
       "      <th>FW_chk_x</th>\n",
       "      <th>count_sent_x</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_y</th>\n",
       "      <th>LW_y</th>\n",
       "      <th>FW_y</th>\n",
       "      <th>LW_chk_y</th>\n",
       "      <th>FW_chk_y</th>\n",
       "      <th>count_sent_y</th>\n",
       "      <th>counter_y</th>\n",
       "      <th>word_location_y</th>\n",
       "      <th>word_mapping_y</th>\n",
       "      <th>words_combined_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993916</td>\n",
       "      <td>13270</td>\n",
       "      <td>84248</td>\n",
       "      <td>defectMW</td>\n",
       "      <td>I-indications</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>MW</td>\n",
       "      <td>defectMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492633</td>\n",
       "      <td>3288</td>\n",
       "      <td>20785</td>\n",
       "      <td>treesMW</td>\n",
       "      <td>O</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>MW</td>\n",
       "      <td>treesMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3699630</td>\n",
       "      <td>24463</td>\n",
       "      <td>155711</td>\n",
       "      <td>weaknessesMW</td>\n",
       "      <td>O</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>MW</td>\n",
       "      <td>weaknessesMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>835859</td>\n",
       "      <td>5559</td>\n",
       "      <td>35167</td>\n",
       "      <td>locationMW</td>\n",
       "      <td>O</td>\n",
       "      <td>n</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>n</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>MW</td>\n",
       "      <td>locationMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4197872</td>\n",
       "      <td>27740</td>\n",
       "      <td>176808</td>\n",
       "      <td>sindMW</td>\n",
       "      <td>O</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>MW</td>\n",
       "      <td>sindMW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Doc_ID_x  Sent_ID_x        Word_x          tag_x LW_x FW_x  \\\n",
       "0  1993916     13270      84248      defectMW  I-indications    t    d   \n",
       "1   492633      3288      20785       treesMW              O    s    t   \n",
       "2  3699630     24463     155711  weaknessesMW              O    s    w   \n",
       "3   835859      5559      35167    locationMW              O    n    l   \n",
       "4  4197872     27740     176808        sindMW              O    d    s   \n",
       "\n",
       "   LW_chk_x  FW_chk_x  count_sent_x        ...         tag_y  LW_y FW_y  \\\n",
       "0         1         1             9        ...             O     t    d   \n",
       "1         1         1            27        ...             O     s    t   \n",
       "2         1         1            51        ...             O     s    w   \n",
       "3         1         1            16        ...             O     n    l   \n",
       "4         1         1            14        ...             O     d    s   \n",
       "\n",
       "  LW_chk_y FW_chk_y count_sent_y counter_y  word_location_y  word_mapping_y  \\\n",
       "0        1        1            9         8         0.888889              MW   \n",
       "1        1        1           27        18         0.666667              MW   \n",
       "2        1        1           51        38         0.745098              MW   \n",
       "3        1        1           16         8         0.500000              MW   \n",
       "4        1        1           14         5         0.357143              MW   \n",
       "\n",
       "   words_combined_y  \n",
       "0          defectMW  \n",
       "1           treesMW  \n",
       "2      weaknessesMW  \n",
       "3        locationMW  \n",
       "4            sindMW  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING THE FINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df['LW'] = final_df['Word'].str[-1:]\n",
    "final_df['FW'] = final_df['Word'].str[:1]\n",
    "final_df['LW_chk'] = np.where(((final_df['LW'] == (\"(\",\")\",\"'\",\",\",\"`\",\"?\",\";\",\"-\",\":\",\"/\",\"’\",\"-\",\"[\",\"]\")) |\n",
    "                              final_df['LW'].str[0].str.isalnum()), 1, 0)\n",
    "final_df['FW_chk'] = np.where(((final_df['FW'] == (\"(\",\")\",\"'\",\",\",\"`\",\"?\",\";\",\"-\",\":\",\"/\",\"’\",\"-\",\"[\",\"]\")) |\n",
    "                              final_df['FW'].str[0].str.isalnum()), 1, 0)\n",
    "\n",
    "length=final_df.groupby('Sent_ID', as_index=False).agg(\"count\")\n",
    "final_df = final_df.merge(length, on = \"Sent_ID\", how=\"left\").drop(['Word_y','Doc_ID_y','LW_y','FW_y',\n",
    "                                                                         'LW_chk_y','FW_chk_y'],axis = 1)\n",
    "\n",
    "final_df = final_df.rename(columns = {\"id_x\": \"id\", \"Doc_ID_x\":\"Doc_ID\", \"Word_x\": \"Word\",\n",
    "                                                \"LW_x\":\"LW\", \"FW_x\": \"FW\",\n",
    "                                               \"LW_chk_x\": \"LW_chk\", \"FW_chk_x\": \"FW_chk\", \"id_y\":\"count_sent\"})\n",
    "\n",
    "final_df['counter']=1\n",
    "final_df['counter'] = final_df.groupby('Sent_ID').counter.cumsum()\n",
    "\n",
    "final_df['word_location']=final_df['counter']/final_df['count_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>LW</th>\n",
       "      <th>FW</th>\n",
       "      <th>LW_chk</th>\n",
       "      <th>FW_chk</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>counter</th>\n",
       "      <th>word_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4543834</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>CCCVA</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4543835</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4543836</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>MANOVA</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4543837</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4543838</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>my</td>\n",
       "      <td>y</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Doc_ID  Sent_ID    Word LW FW  LW_chk  FW_chk  count_sent  \\\n",
       "0  4543834   30001   191283   CCCVA  A  C       1       1           8   \n",
       "1  4543835   30001   191283       ,  ,  ,       0       0           8   \n",
       "2  4543836   30001   191283  MANOVA  A  M       1       1           8   \n",
       "3  4543837   30001   191283       ,  ,  ,       0       0           8   \n",
       "4  4543838   30001   191283      my  y  m       1       1           8   \n",
       "\n",
       "   counter  word_location  \n",
       "0        1          0.125  \n",
       "1        2          0.250  \n",
       "2        3          0.375  \n",
       "3        4          0.500  \n",
       "4        5          0.625  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_df[\"word_mapping\"] = final_df[\"word_location\"].apply(lambda x: \"SW\" if x<=0.01 else(\"LW\" if x>=0.99 else \"MW\"))\n",
    "final_df['words_combined'] = final_df[['Word', 'word_mapping']].apply(lambda x : '{}{}'.format(x[0],x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_df['Word']=final_df['words_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_counts = vectorizer.transform(final_df['Word'].values.astype('U'))\n",
    "predictions_2 = classifier.predict(final_counts)\n",
    "\n",
    "final_df[\"tag\"]=predictions_2\n",
    "final_df2=final_df[['id','Sent_ID','tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_df['tag'] = np.where(final_df['LW_chk']==0, 'O', final_df['tag'])\n",
    "final_df['tag'] = np.where(final_df['FW_chk']==0, 'O', final_df['tag'])\n",
    "final_df2=final_df[['id','Sent_ID','tag']]\n",
    "\n",
    "final_df2.to_csv('C:\\\\Extras\\\\DataScience\\\\Hackathon1\\\\final_sub\\\\sample_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
